---
title: "è·å–å›¾ç‰‡å¹¶æŒä¹…åŒ–"
---

TextIn xParseä¸ºäº†ä¿æŠ¤æ‚¨çš„æ•°æ®éšç§å®‰å…¨ï¼Œä»æ–‡æ¡£è§£æAPIè¿”å›çš„å›¾ç‰‡é“¾æ¥æœ‰æ•ˆæœŸä¸º30å¤©ï¼Œ30å¤©åå¹³å°ä¼šè‡ªåŠ¨åˆ é™¤å›¾ç‰‡èµ„æºã€‚å¦‚æœæ‚¨æƒ³è¦è·å–å›¾ç‰‡ä¿å­˜åˆ°æœ¬åœ°å¹¶ä½¿markdownä¸­çš„å›¾ç‰‡é“¾æ¥æŒä¹…åŒ–ï¼Œä»¥ä¾¿æ‚¨åœ¨ä¸‹æ¸¸è¯¸å¦‚çŸ¥è¯†åº“é—®ç­”ç­‰AIåº”ç”¨ä¸­é•¿æœŸç¨³å®šåœ°ä¸ºç”¨æˆ·å±•ç¤ºå›¾ç‰‡ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§æ–¹æ³•ä¾›æ‚¨é€‰æ‹©ï¼š

1. è®¾ç½®URLå‚æ•°[image-output-type](https://docs.textin.com/api-reference/endpoint/parse#parameter-image-output-type)ä¸ºbase64strï¼Œæ­¤æ—¶å›¾ç‰‡ç›´æ¥ä»¥base64æ ¼å¼åœ¨APIç»“æœä¸­è¿”å›ã€‚ï¼ˆè¿™ç§æ–¹å¼è¿”å›ç»“æœä½“ç§¯ä¼šå¾ˆå¤§ï¼Œé•¿æ–‡æ¡£ä¸æ¨èï¼‰
2. è®¾ç½®URLå‚æ•°[image-output-type](https://docs.textin.com/api-reference/endpoint/parse#parameter-image-output-type)ä¸ºdefaultï¼ˆä¸ä¼ æ—¶é»˜è®¤ä¸ºè¯¥å€¼ï¼‰ï¼Œæ­¤æ—¶å›¾ç‰‡ç›´æ¥ä»¥TextInå¹³å°çš„é“¾æ¥æ–¹å¼è¿”å›ï¼Œæ‚¨å¯ä»¥é€šè¿‡é“¾æ¥ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œæˆ–ä¸Šä¼ åˆ°æ‚¨çš„äº‘å­˜å‚¨ã€‚

## å¦‚ä½•å°†markdownä¸­çš„å›¾ç‰‡é“¾æ¥æ›¿æ¢ä¸ºæœ¬åœ°å›¾ç‰‡é“¾æ¥

**æ‚¨å¯ä»¥å‚è€ƒå¦‚ä¸‹æ•™ç¨‹ï¼šä½¿ç”¨ä¸Šè¿°æ–¹æ³•2è®©APIè¿”å›å›¾ç‰‡é“¾æ¥ï¼Œå¹¶å®Œæˆmarkdownä¸­çš„å›¾ç‰‡é“¾æ¥æ›¿æ¢ã€‚**

<Tip>
  è¿™é‡Œä¸ºæ‚¨æä¾›äº†ä¸€ä»½Textinå®˜æ–¹pdfç¤ºä¾‹æ–‡ä»¶ï¼Œæ‚¨å¯ç‚¹å‡»ä¸‹è½½æˆ–ä½¿ç”¨è¯¥é“¾æ¥ï¼š[æ–‡æ¡£è§£æpdfç¤ºä¾‹.pdf](https://web-api.textin.com/open/image/download?filename=c9cf7431eb314c7ba3f43ee716c799a3)
</Tip>

- å‚è€ƒ[å¿«é€Ÿå¯åŠ¨](/xparse/parse-quickstart)ï¼Œåœ¨ options ä¸­è®¾ç½®å‚æ•° get_image ä¸º objects æˆ– bothï¼Œè®©APIè¿”å›é¡µé¢å†…çš„å›¾ç‰‡å¯¹è±¡ï¼›è®¾ç½®å‚æ•° image_output_type ä¸º  defaultï¼ŒAPIä¼šè¿”å›å›¾ç‰‡URLã€‚å¦‚ä¸‹å›¾ï¼š

![Parse Image Ori Pn](/images/parse-image-ori.png)

- å‚è€ƒå¦‚ä¸‹ç¤ºä¾‹ä»£ç ï¼šæå–è¿”å›ç»“æœmarkdownä¸­çš„å›¾ç‰‡URLå°†å›¾ç‰‡ä¸‹è½½ä¿å­˜è‡³æœ¬åœ°ï¼Œå¹¶å°†markdownä¸­çš„å›¾ç‰‡é“¾æ¥æ›¿æ¢ä¸ºæœ¬åœ°å›¾ç‰‡é“¾æ¥ã€‚

```python
import os
import re
import requests
import hashlib
from urllib.parse import urlparse
from pathlib import Path
import time
from typing import List, Tuple, Optional

class ImageDownloader:
    def __init__(self, md_file: str, images_dir: str = "images"):
        """
        åˆå§‹åŒ–å›¾ç‰‡ä¸‹è½½å™¨
        
        Args:
            md_file: markdownæ–‡ä»¶è·¯å¾„
            images_dir: å›¾ç‰‡å­˜å‚¨ç›®å½•
        """
        self.md_file = md_file
        self.images_dir = images_dir
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # åˆ›å»ºå›¾ç‰‡ç›®å½•
        Path(self.images_dir).mkdir(exist_ok=True)
    
    def extract_image_urls(self, content: str) -> List[Tuple[str, str]]:
        """
        æå–markdownå†…å®¹ä¸­çš„å›¾ç‰‡é“¾æ¥
        
        Args:
            content: markdownæ–‡ä»¶å†…å®¹
            
        Returns:
            (å®Œæ•´çš„markdownè¯­æ³•, å›¾ç‰‡URL) çš„å…ƒç»„åˆ—è¡¨
        """
        # åŒ¹é… ![...](https://...) æ ¼å¼çš„markdownå›¾ç‰‡è¯­æ³•
        pattern = r'!\[([^\]]*)\]\((https://[^\s\)]+\.(?:jpg|jpeg|png|gif|bmp|webp|svg))\)'
        matches = re.findall(pattern, content, re.IGNORECASE)
        
        # è¿”å›å®Œæ•´çš„markdownè¯­æ³•å’ŒURL
        result = []
        for alt_text, url in matches:
            full_markdown = f"![{alt_text}]({url})"
            result.append((full_markdown, url))
        
        return result
    
    def generate_filename(self, url: str) -> str:
        """
        æ ¹æ®URLç”Ÿæˆæœ¬åœ°æ–‡ä»¶å
        
        Args:
            url: å›¾ç‰‡URL
            
        Returns:
            æœ¬åœ°æ–‡ä»¶å
        """
        # è§£æURLè·å–æ–‡ä»¶å
        parsed_url = urlparse(url)
        original_filename = os.path.basename(parsed_url.path)
        
        # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œä»URLä¸­æå–
        if not original_filename or '.' not in original_filename:
            # ä½¿ç”¨URLçš„MD5å“ˆå¸Œä½œä¸ºæ–‡ä»¶å
            url_hash = hashlib.md5(url.encode()).hexdigest()[:12]
            original_filename = f"{url_hash}.jpg"  # é»˜è®¤ä¸ºjpg
        
        return original_filename
    
    def download_image(self, url: str, max_retries: int = 3) -> Optional[str]:
        """
        ä¸‹è½½å•ä¸ªå›¾ç‰‡
        
        Args:
            url: å›¾ç‰‡URL
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            æˆåŠŸæ—¶è¿”å›æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        filename = self.generate_filename(url)
        local_path = os.path.join(self.images_dir, filename)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
        if os.path.exists(local_path):
            print(f"ğŸ“ æ–‡ä»¶å·²å­˜åœ¨: {local_path}")
            return local_path
        
        for attempt in range(max_retries):
            try:
                print(f"â¬‡ï¸  æ­£åœ¨ä¸‹è½½ ({attempt + 1}/{max_retries}): {url}")
                
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ–‡ä»¶
                content_type = response.headers.get('content-type', '')
                if not content_type.startswith('image/'):
                    print(f"âš ï¸  è­¦å‘Š: {url} ä¸æ˜¯å›¾ç‰‡æ–‡ä»¶ (Content-Type: {content_type})")
                
                # ä¿å­˜æ–‡ä»¶
                with open(local_path, 'wb') as f:
                    f.write(response.content)
                
                file_size = len(response.content)
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {filename} ({file_size} bytes)")
                return local_path
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)  # é‡è¯•å‰ç­‰å¾…2ç§’
                else:
                    print(f"ğŸ’€ ä¸‹è½½å½»åº•å¤±è´¥: {url}")
                    return None
        
        return None
    
    def process_markdown(self) -> bool:
        """
        å¤„ç†markdownæ–‡ä»¶ï¼Œä¸‹è½½å›¾ç‰‡å¹¶æ›¿æ¢é“¾æ¥
        
        Returns:
            å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            # è¯»å–markdownæ–‡ä»¶
            with open(self.md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_file = f"{self.md_file}.backup"
            with open(backup_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"ğŸ—‚ï¸  å·²åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_file}")
            
            # æå–å›¾ç‰‡é“¾æ¥
            image_data = self.extract_image_urls(content)
            if not image_data:
                print("ğŸ” æœªæ‰¾åˆ°å›¾ç‰‡é“¾æ¥")
                return True
            
            print(f"ğŸ” æ‰¾åˆ° {len(image_data)} ä¸ªå›¾ç‰‡é“¾æ¥")
            
            # ä¸‹è½½å›¾ç‰‡å¹¶æ›¿æ¢é“¾æ¥
            replacements = []
            for i, (markdown_syntax, url) in enumerate(image_data, 1):
                print(f"\nğŸ“‹ å¤„ç†ç¬¬ {i}/{len(image_data)} ä¸ªé“¾æ¥:")
                print(f"ğŸ” åŸå§‹è¯­æ³•: {markdown_syntax}")
                
                local_path = self.download_image(url)
                if local_path:
                    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                    relative_path = os.path.relpath(local_path, os.path.dirname(self.md_file))
                    # ä¿ç•™åŸå§‹çš„alt textï¼Œåªæ›¿æ¢URL
                    alt_text = re.search(r'!\[([^\]]*)\]', markdown_syntax).group(1)
                    new_markdown = f"![{alt_text}]({relative_path})"
                    replacements.append((markdown_syntax, new_markdown))
                    print(f"ğŸ”— å°†æ›¿æ¢ä¸º: {new_markdown}")
                else:
                    print(f"âš ï¸  ä¿ç•™åŸå§‹é“¾æ¥: {markdown_syntax}")
            
            # åº”ç”¨æ›¿æ¢
            modified_content = content
            for old_link, new_link in replacements:
                modified_content = modified_content.replace(old_link, new_link)
            
            # ä¿å­˜ä¿®æ”¹åçš„æ–‡ä»¶
            with open(self.md_file, 'w', encoding='utf-8') as f:
                f.write(modified_content)
            
            print(f"\nâœ… å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š æˆåŠŸæ›¿æ¢ {len(replacements)} ä¸ªé“¾æ¥")
            print(f"ğŸ“ å›¾ç‰‡ä¿å­˜åœ¨: {self.images_dir}/")
            print(f"ğŸ“„ åŸæ–‡ä»¶å¤‡ä»½: {backup_file}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return False
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.session.close()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å›¾ç‰‡ä¸‹è½½å™¨å¯åŠ¨")
    print("=" * 50)
    
    # é…ç½®
    md_file = "test.md"  # è¿™é‡Œæ›¿æ¢ä¸ºä½ çš„markdownæ–‡ä»¶è·¯å¾„
    images_dir = "images"  # è¿™é‡Œæ›¿æ¢ä¸ºä½ çš„å›¾ç‰‡å­˜å‚¨ç›®å½•
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(md_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
        return
    
    # åˆ›å»ºä¸‹è½½å™¨å¹¶å¤„ç†
    downloader = ImageDownloader(md_file, images_dir)
    
    try:
        success = downloader.process_markdown()
        if success:
            print("\nğŸ‰ æ‰€æœ‰æ“ä½œå®Œæˆ!")
        else:
            print("\nğŸ’¥ æ“ä½œå¤±è´¥!")
    finally:
        downloader.cleanup()

if __name__ == "__main__":
    main() 
```

- å¦‚ä¸‹å›¾ï¼šå¯ä»¥çœ‹åˆ°å›¾ç‰‡å·²ç»ä¿å­˜åˆ°æœ¬åœ°æŒ‡å®šç›®å½•ä¸‹ï¼Œæ‰“å¼€markdownæ–‡ä»¶å¯ä»¥çœ‹åˆ°å›¾ç‰‡é“¾æ¥å·²ç»æ›¿æ¢ä¸ºæœ¬åœ°å›¾ç‰‡é“¾æ¥ã€‚

![Parse Image Re Pn](/images/parse-image-re.png)